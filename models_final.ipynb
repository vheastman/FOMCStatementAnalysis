{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "Here are the final models and results. Many other things were tried and most I saved in the `models_failed.py`, but some were even deleted from there. The data was processed in `process_data.py` and details of the statements were explored in `EDA.py`. \n",
    "\n",
    "The purpose of this analysis was to determine word clustering for the 141 statements issued by the FOMC. Relatedly, I attempt to train a model to predict statement 'sentiment'. I measure sentiment by the daily change in the 10-year treasury yield after the statement is released. \n",
    "\n",
    "For the clustering analysis, I found the straight CountVectorizer was the best way to extract features. For the sentiment analysis, I used TfidfVectorizer, which is the same as CountVectorizer followed by the TfidfTransformer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import sklearn libraries\n",
    "from sklearn import svm\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.feature_extraction.text as text\n",
    "import sklearn.naive_bayes as nb\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0        date                                               text  \\\n",
      "0           0  1994-02-04  Chairman Alan Greenspan announced today that t...   \n",
      "1           1  1994-03-22  Chairman Alan Greenspan announced today that t...   \n",
      "2           2  1994-04-18  Chairman Alan Greenspan announced today that t...   \n",
      "3           3  1994-05-17  The Federal Reserve today announced two action...   \n",
      "4           4  1994-08-16  The Federal Reserve announced today the follow...   \n",
      "\n",
      "   labels  \n",
      "0       1  \n",
      "1       0  \n",
      "2       1  \n",
      "3       0  \n",
      "4       0  \n",
      "1    91\n",
      "0    80\n",
      "Name: labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Read in the statements\n",
    "statements = pd.read_csv(\"statements_with_labels.csv\")\n",
    "print(statements.head())\n",
    "print(statements.labels.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171, 1595)\n"
     ]
    }
   ],
   "source": [
    "# Extract features with CountVectorizer\n",
    "# Ignore words with over 95% frequency and in less than 2 documents\n",
    "vec = CountVectorizer(max_df=0.95, min_df=1, stop_words='english')\n",
    "\n",
    "cv = vec.fit_transform(statements['text'])\n",
    "print(cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    unique_top_words = []\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "        unique_top_words.extend([feature_names[i] for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "    print()\n",
    "    return set(unique_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model:\n",
      "Topic #0: bank growth inflation markets action policy risks chairman central monetary\n",
      "Topic #1: inflation policy securities labor conditions longer funds agency term monetary\n",
      "Topic #2: markets credit facility reserve lending growth resource financial conditions securities\n",
      "Topic #3: growth action inflation discount today markets pressures reserve approved potential\n",
      "Topic #4: action growth policy inflation chairman monetary approved basis board risks\n",
      "\n",
      "\n",
      "{'financial', 'potential', 'lending', 'monetary', 'bank', 'securities', 'discount', 'labor', 'resource', 'action', 'conditions', 'agency', 'pressures', 'policy', 'risks', 'inflation', 'chairman', 'board', 'markets', 'approved', 'basis', 'central', 'today', 'term', 'credit', 'growth', 'longer', 'facility', 'funds', 'reserve'}\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "lda_model = LatentDirichletAllocation(n_components=5, max_iter=5,\n",
    "                                      learning_method='online',\n",
    "                                      learning_offset=50.,\n",
    "                                      random_state=0)\n",
    "lda_model.fit(cv)\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "feature_names = vec.get_feature_names()\n",
    "unique = print_top_words(lda_model, feature_names, 10)\n",
    "print()\n",
    "print(unique)\n",
    "print(len(unique))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Sentiment Analysis\n",
    "\n",
    "#### II (a). Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171, 1764)\n"
     ]
    }
   ],
   "source": [
    "# Identify labels\n",
    "y = statements['labels']\n",
    "\n",
    "# Implement Tfid vectorizer\n",
    "tf = text.TfidfVectorizer()\n",
    "X = tf.fit_transform(statements['text'])\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each sample has ~11.18% non-zero features.\n"
     ]
    }
   ],
   "source": [
    "# Identify how many samples have non-zero features\n",
    "p = 100 * X.nnz / float(X.shape[0] * X.shape[1])\n",
    "print(f\"Each sample has ~{p:.2f}% non-zero features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate train/test data\n",
    "(X_train, X_test, y_train, y_test) = ms.train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': array([  1.00000e-02,   1.20679e-02,   1.45635e-02,   1.75751e-02,\n",
       "         2.12095e-02,   2.55955e-02,   3.08884e-02,   3.72759e-02,\n",
       "         4.49843e-02,   5.42868e-02,   6.55129e-02,   7.90604e-02,\n",
       "         9.54095e-02,   1.15140e-01,   1.38950e-01,   1.67683e-01,\n",
       "         2....    3.90694e+01,   4.71487e+01,   5.68987e+01,   6.86649e+01,\n",
       "         8.28643e+01,   1.00000e+02])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use GridSearchCV to find optimal alpha\n",
    "nb_model = ms.GridSearchCV(nb.BernoulliNB(), param_grid={'alpha': np.logspace(-2., 2., 50)})\n",
    "nb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62857142857142856"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II (b). SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use GridSearchCV \n",
    "svm_model = ms.GridSearchCV(svm.SVC(kernel='rbf'), \n",
    "                            {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma' : [0.001, 0.01, 0.1, 1]}, \n",
    "                            cv=5)\n",
    "svm_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.59999999999999998"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: run SVM and NB on CountVectorized features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = ms.train_test_split(cv, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37142857142857144"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use GridSearchCV \n",
    "svm_model = ms.GridSearchCV(svm.SVC(kernel='rbf'), \n",
    "                            {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma' : [0.001, 0.01, 0.1, 1]}, \n",
    "                            cv=5)\n",
    "svm_model.fit(X_train, y_train)\n",
    "svm_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48571428571428571"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use GridSearchCV to find optimal alpha\n",
    "nb_model = ms.GridSearchCV(nb.BernoulliNB(), param_grid={'alpha': np.logspace(-2., 2., 50)})\n",
    "nb_model.fit(X_train, y_train)\n",
    "nb_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test: Run LDA on tf-idf features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topics in LDA model:\n",
      "Topic #0: the of will to in inflation federal weather action its\n",
      "Topic #1: the of to and in committee inflation federal its will\n",
      "Topic #2: elevating evaluate improvement mixed announcement chain to weakened unlikely work\n",
      "Topic #3: the geithner owing future inflation from high signs soften likely\n",
      "Topic #4: the of and to committee in inflation will its securities\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's test LDA on the tf-idf vectorized features\n",
    "lda_model = LatentDirichletAllocation(n_components=5, max_iter=5,\n",
    "                                      learning_method='online',\n",
    "                                      learning_offset=50.,\n",
    "                                      random_state=0)\n",
    "lda_model.fit(X)\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "feature_names = tf.get_feature_names()\n",
    "print_top_words(lda_model, feature_names, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
